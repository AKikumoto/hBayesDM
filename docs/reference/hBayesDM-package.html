<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Hierarchical Bayesian Modeling of Decision-Making Tasks — hBayesDM-package • hBayesDM</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="Hierarchical Bayesian Modeling of Decision-Making Tasks — hBayesDM-package" />

<meta property="og:description" content="Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.

 Bandit2-Armed Bandit (Rescorla-Wagner (delta)) --- bandit2arm_delta 
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) --- bandit4arm_4par 
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) --- bandit4arm_lapse
 Delay DiscountingConstant Sensitivity --- dd_cs 
                                   Constant Sensitivity for single subject --- dd_cs_single 
                                   Exponential --- dd_exp 
                                   Hyperbolic --- dd_hyperbolic 
                                   Hyperbolic for single subject --- dd_hyperbolic_single
 Orthogonalized Go/NogoRW + Noise --- gng_m1 
                                        RW + Noise + Bias --- gng_m2 
                                        RW + Noise + Bias + Pavlovian Bias --- gng_m3 
                                        RW(modified) + Noise + Bias + Pavlovian Bias --- gng_m4
 Iowa GamblingProspect Valence Learning-DecayRI --- igt_pvl_decay 
                               Prospect Valence Learning-Delta --- igt_pvl_delta 
                               Value-Plus_Perseverance --- igt_vpp
 Peer influence taskOCU model --- peer_ocu
 Probabilistic Reversal LearningFictitious Update --- prl_fictitious 
                                                 Fictitious Update w/o alpha (indecision point) --- prl_fictitious_woa 
                                                 Fictitious Update and multiple blocks per subject --- prl_fictitious_multipleB 
                                                 Experience-Weighted Attraction --- prl_ewa 
                                                 Reward-Punishment --- prl_rp 
                                                 Reward-Punishment and multiple blocks per subject --- prl_rp_multipleB 
                                                 Fictitious Update with separate learning for Reward-Punishment --- prl_fictitious_rp 
                                                 Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) --- prl_fictitious_rp_woa
 Risk AversionProspect Theory (PT) --- ra_prospect 
                               PT without a loss aversion parameter --- ra_noLA 
                               PT without a risk aversion parameter --- ra_noRA
 Ultimatum GameIdeal Bayesian Observer --- ug_bayes 
                                Rescorla-Wagner (delta) --- ug_delta
 Choice/Reaction timeDrift Diffusion Model --- choiceRT_ddm 
                                      Drift Diffusion Model for single subject --- choiceRT_ddm_single 
                                      Linear Ballistic Accumulator --- choiceRT_lba 
                                      Linear Ballistic Accumulator for single subject --- choiceRT_lba_single
 Two-Step taskFull model (7 parameters) --- ts_par7 
                               6 parameter model (without eligibility trace, lambda) --- ts_par6 
                               4 parameter model --- ts_par4" />

<meta property="og:description" content="" />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">hBayesDM</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">0.6.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Hierarchical Bayesian Modeling of Decision-Making Tasks</h1>
    
    <div class="hidden name"><code>hBayesDM-package.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Fit an array of decision-making tasks with computational models in a hierarchical Bayesian framework. Can perform hierarchical Bayesian analysis of various computational models with a single line of coding.
Bolded tasks, followed by their respective models, are itemized below.</p>
<dl class='dl-horizontal'>
 <dt><strong>Bandit</strong></dt><dd><p>2-Armed Bandit (Rescorla-Wagner (delta)) --- <a href='bandit2arm_delta.html'>bandit2arm_delta</a> <br />
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity (Rescorla-Wagner (delta)) --- <a href='bandit4arm_4par.html'>bandit4arm_4par</a> <br />
                        4-Armed Bandit with fictive updating + reward/punishment sensitvity + lapse (Rescorla-Wagner (delta)) --- <a href='bandit4arm_lapse.html'>bandit4arm_lapse</a></p></dd>
 <dt><strong>Delay Discounting</strong></dt><dd><p>Constant Sensitivity --- <a href='dd_cs.html'>dd_cs</a> <br />
                                   Constant Sensitivity for single subject --- <a href='dd_cs_single.html'>dd_cs_single</a> <br />
                                   Exponential --- <a href='dd_exp.html'>dd_exp</a> <br />
                                   Hyperbolic --- <a href='dd_hyperbolic.html'>dd_hyperbolic</a> <br />
                                   Hyperbolic for single subject --- <a href='dd_hyperbolic_single.html'>dd_hyperbolic_single</a></p></dd>
 <dt><strong>Orthogonalized Go/Nogo</strong></dt><dd><p>RW + Noise --- <a href='gng_m1.html'>gng_m1</a> <br />
                                        RW + Noise + Bias --- <a href='gng_m2.html'>gng_m2</a> <br />
                                        RW + Noise + Bias + Pavlovian Bias --- <a href='gng_m3.html'>gng_m3</a> <br />
                                        RW(modified) + Noise + Bias + Pavlovian Bias --- <a href='gng_m4.html'>gng_m4</a></p></dd>
 <dt><strong>Iowa Gambling</strong></dt><dd><p>Prospect Valence Learning-DecayRI --- <a href='igt_pvl_decay.html'>igt_pvl_decay</a> <br />
                               Prospect Valence Learning-Delta --- <a href='igt_pvl_delta.html'>igt_pvl_delta</a> <br />
                               Value-Plus_Perseverance --- <a href='igt_vpp.html'>igt_vpp</a></p></dd>
 <dt><strong>Peer influence task</strong></dt><dd><p>OCU model --- <a href='peer_ocu.html'>peer_ocu</a></p></dd>
 <dt><strong>Probabilistic Reversal Learning</strong></dt><dd><p>Fictitious Update --- <a href='prl_fictitious.html'>prl_fictitious</a> <br />
                                                 Fictitious Update w/o alpha (indecision point) --- <a href='prl_fictitious_woa.html'>prl_fictitious_woa</a> <br />
                                                 Fictitious Update and multiple blocks per subject --- <a href='prl_fictitious_multipleB.html'>prl_fictitious_multipleB</a> <br />
                                                 Experience-Weighted Attraction --- <a href='prl_ewa.html'>prl_ewa</a> <br />
                                                 Reward-Punishment --- <a href='prl_rp.html'>prl_rp</a> <br />
                                                 Reward-Punishment and multiple blocks per subject --- <a href='prl_rp_multipleB.html'>prl_rp_multipleB</a> <br />
                                                 Fictitious Update with separate learning for Reward-Punishment --- <a href='prl_fictitious_rp.html'>prl_fictitious_rp</a> <br />
                                                 Fictitious Update with separate learning for Reward-Punishment w/o alpha (indecision point) --- <a href='prl_fictitious_rp_woa.html'>prl_fictitious_rp_woa</a></p></dd>
 <dt><strong>Risk Aversion</strong></dt><dd><p>Prospect Theory (PT) --- <a href='ra_prospect.html'>ra_prospect</a> <br />
                               PT without a loss aversion parameter --- <a href='ra_noLA.html'>ra_noLA</a> <br />
                               PT without a risk aversion parameter --- <a href='ra_noRA.html'>ra_noRA</a></p></dd>
 <dt><strong>Ultimatum Game</strong></dt><dd><p>Ideal Bayesian Observer --- <a href='ug_bayes.html'>ug_bayes</a> <br />
                                Rescorla-Wagner (delta) --- <a href='ug_delta.html'>ug_delta</a></p></dd>
 <dt><strong>Choice/Reaction time</strong></dt><dd><p>Drift Diffusion Model --- <a href='choiceRT_ddm.html'>choiceRT_ddm</a> <br />
                                      Drift Diffusion Model for single subject --- <a href='choiceRT_ddm_single.html'>choiceRT_ddm_single</a> <br />
                                      Linear Ballistic Accumulator --- <a href='choiceRT_lba.html'>choiceRT_lba</a> <br />
                                      Linear Ballistic Accumulator for single subject --- <a href='choiceRT_lba_single.html'>choiceRT_lba_single</a></p></dd>
 <dt><strong>Two-Step task</strong></dt><dd><p>Full model (7 parameters) --- <a href='ts_par7.html'>ts_par7</a> <br />
                               6 parameter model (without eligibility trace, lambda) --- <a href='ts_par6.html'>ts_par6</a> <br />
                               4 parameter model --- <a href='ts_par4.html'>ts_par4</a></p></dd>

    </dl>
    
    </div>

        
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Please cite as: 
Ahn, W.-Y., Haines, N., &amp; Zhang, L. (2017). Revealing neuro-computational mechanisms of reinforcement learning and decision-making with the hBayesDM package. <em>Computational Psychiatry</em>. 1, 24-57. https://doi.org/10.1162/CPSY_a_00002</p>
    
    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>For tutorials and further readings, visit : <a href='http://rpubs.com/CCSL/hBayesDM'>http://rpubs.com/CCSL/hBayesDM</a>.</p></div>
    

  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      
      <li><a href="#references">References</a></li>

      <li><a href="#see-also">See also</a></li>
          </ul>

    <h2>Author</h2>
    
Woo-Young Ahn <a href='mailto:wooyoung.ahn@gmail.com'>wooyoung.ahn@gmail.com</a>

Nathaniel Haines <a href='mailto:haines.175@osu.edu'>haines.175@osu.edu</a>

Lei Zhang <a href='mailto:bnuzhanglei2008@gmail.com'>bnuzhanglei2008@gmail.com</a>

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Woo-Young Ahn, Nate Haines, Lei Zhang.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

